# MLOps Chatbot Project

GPU ìì›ì„ í™œìš©í•œ ì»¤ìŠ¤í…€ ì±—ë´‡ êµ¬ì¶• í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. LLM Fine-tuningë¶€í„° í”„ë¡œë•ì…˜ ë°°í¬ê¹Œì§€ ì „ì²´ MLOps íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

## í˜„ì¬ ìƒíƒœ

- **Phase**: 2 (Fine-tuning ì™„ë£Œ)
- **ë² ì´ìŠ¤ ëª¨ë¸**: LLaMA-3-8B-Instruct
- **GPU**: RTX 5090 (31GB) + RTX 5060 Ti (15GB)
- **ë°°í¬ëœ ëª¨ë¸**: [2shlee/llama3-8b-ko-chat-v1](https://huggingface.co/2shlee/llama3-8b-ko-chat-v1)

## í”„ë¡œì íŠ¸ ëª©í‘œ

1. **LLM Fine-tuning**: LoRA/QLoRAë¥¼ í™œìš©í•œ íš¨ìœ¨ì  í•™ìŠµ
2. **ê³ ì„±ëŠ¥ ì„œë¹™**: vLLMì„ ì´ìš©í•œ ìµœì í™”ëœ ì¶”ë¡ 
3. **End-to-End MLOps**: ë°ì´í„° ìˆ˜ì§‘ â†’ í•™ìŠµ â†’ ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§
4. **í”„ë¡œë•ì…˜ í™˜ê²½ êµ¬ì¶•**: FastAPI + Docker + CI/CD

## ê¸°ìˆ  ìŠ¤íƒ

| ë¶„ë¥˜ | ê¸°ìˆ  |
|------|------|
| Core ML | PyTorch 2.1+, Transformers 4.35+, PEFT, bitsandbytes |
| Serving | vLLM, FastAPI, Gradio, SQLAdmin |
| MLOps | MLflow, DVC, LangChain |
| Monitoring | Prometheus, Grafana, Alloy, Loki, structlog |
| DevOps | Docker, Docker Compose |
| Database | SQLAlchemy 2.0+, Alembic (ë§ˆì´ê·¸ë ˆì´ì…˜), SQLite |
| Config | pydantic-settings |

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
mlops-project/
â”œâ”€â”€ docker/                     # Docker Compose íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ docker-compose.yml          # ì „ì²´ ìŠ¤íƒ ì‹¤í–‰
â”‚   â”œâ”€â”€ docker-compose.mlflow.yml   # MLflow Stack
â”‚   â”œâ”€â”€ docker-compose.serving.yml  # Serving Stack
â”‚   â”œâ”€â”€ docker-compose.monitoring.yml # Monitoring Stack
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ deployment/                 # ìŠ¤íƒë³„ Dockerfile/Config
â”‚   â”œâ”€â”€ mlflow/                     # MLflow Dockerfile
â”‚   â”œâ”€â”€ serving/                    # vLLM, FastAPI Dockerfile
â”‚   â”œâ”€â”€ monitoring/                 # Prometheus, Grafana, Loki, Alloy configs
â”‚   â””â”€â”€ train/                      # Training Dockerfile
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train/                  # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ serve/                  # FastAPI ì„œë¹™ (í´ë¦° ì•„í‚¤í…ì²˜)
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ database.py             # SQLAlchemy ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ admin/                  # SQLAdmin ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ migrations/             # Alembic ë§ˆì´ê·¸ë ˆì´ì…˜
â”‚   â”‚   â”œâ”€â”€ core/                   # ì„¤ì •, LLM í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ models/                 # ORM ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ schemas/                # Pydantic ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â”œâ”€â”€ cruds/                  # DB CRUD í•¨ìˆ˜
â”‚   â”‚   â””â”€â”€ routers/                # API ë¼ìš°í„°
â”‚   â”œâ”€â”€ data/                   # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ evaluate/               # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ utils/                  # ìœ í‹¸ë¦¬í‹° (ë¡œê¹… ë“±)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ references/             # ì°¸ì¡° ê°€ì´ë“œ (LOGGING.md, VLLM.md)
â”‚   â””â”€â”€ plans/                  # ë¦¬íŒ©í† ë§ ê³„íš ë¬¸ì„œ
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ base/                   # HuggingFace ìºì‹œ
â”‚   â”œâ”€â”€ downloaded/             # HF Hubì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸
â”‚   â””â”€â”€ fine-tuned/             # LoRA ì–´ëŒ‘í„° ì €ì¥
â”œâ”€â”€ data/                       # í•™ìŠµ ë°ì´í„°
â”œâ”€â”€ results/                    # ì‹¤í—˜ ê²°ê³¼
â”œâ”€â”€ mlruns/                     # MLflow ì‹¤í—˜ ì €ì¥ì†Œ
â”œâ”€â”€ logs/                       # êµ¬ì¡°í™”ëœ ë¡œê·¸ (JSON)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ë°°í¬ ë° ëª¨ë‹ˆí„°ë§

ì´ í”„ë¡œì íŠ¸ëŠ” Docker Compose ê¸°ë°˜ì˜ ì™„ì „í•œ MLOps ìŠ¤íƒì„ ì œê³µí•©ë‹ˆë‹¤:

### ì„œë¹„ìŠ¤ êµ¬ì„±
- **MLflow Stack**: MLflow ì„œë²„ + PostgreSQL + MinIO
- **Serving Stack**: vLLM GPU ì„œë²„ + FastAPI ê²Œì´íŠ¸ì›¨ì´
- **Monitoring Stack**: Prometheus + Grafana + Loki + Alloy

### ë¡œê¹… ì‹œìŠ¤í…œ
êµ¬ì¡°í™”ëœ JSON ë¡œê¹…ìœ¼ë¡œ ë‹¤ìŒì„ ì¶”ì í•©ë‹ˆë‹¤:
- **Training Logs**: epoch, step, loss, learning_rate, gpu_memory
- **Inference Logs**: latency, tokens_generated, throughput
- **System Logs**: gpu_utilization, memory_usage, temperature
- **API Logs**: http_method, status_code, response_time

### Grafana ëŒ€ì‹œë³´ë“œ
ì‚¬ì „ êµ¬ì„±ëœ 6ê°œì˜ ëŒ€ì‹œë³´ë“œ:
1. **System Overview** - GPU/CPU/ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
2. **Training Metrics** - í•™ìŠµ ì§„í–‰ë¥  ë° Loss ì¶”ì 
3. **Inference Metrics** - QPS, ë ˆì´í„´ì‹œ, ì²˜ë¦¬ëŸ‰
4. **Training Detail** - ì‹¤í—˜ë³„ ìƒì„¸ ë¶„ì„ (ë“œë¦´ë‹¤ìš´)
5. **Inference Detail** - ì—”ë“œí¬ì¸íŠ¸/ëª¨ë¸ë³„ ë¶„ì„ (ë“œë¦´ë‹¤ìš´)
6. **Logs Dashboard** - í†µí•© ë¡œê·¸ ë·°ì–´ (LogQL)

> ğŸ“– **ì „ì²´ ë°°í¬ ê°€ì´ë“œ**: [deployment/README.md](deployment/README.md)ì—ì„œ ì„¤ì¹˜, ì„¤ì •, ë°±ì—…, ì„±ëŠ¥ íŠœë‹, íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë“± ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.

## ì‹œì‘í•˜ê¸°

### 1. í™˜ê²½ ì¤€ë¹„

```bash
# Python ê°€ìƒí™˜ê²½ ìƒì„± (Python 3.10+ í•„ìš”)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install --upgrade pip
pip install -r requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ í•„ìš”í•œ í† í° ì…ë ¥
```

**ì£¼ìš” í™˜ê²½ë³€ìˆ˜:**

| ë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `DEBUG` | ë””ë²„ê·¸ ëª¨ë“œ | `false` |
| `FASTAPI_PORT` | FastAPI í¬íŠ¸ | `8080` |
| `VLLM_BASE_URL` | vLLM ì„œë²„ | `http://localhost:8000/v1` |
| `DEFAULT_MODEL` | ê¸°ë³¸ ëª¨ë¸ (ë¯¸ì„¤ì • ì‹œ vLLM ê¸°ë³¸ê°’) | - |
| `DATABASE_URL` | DB ì—°ê²° | `sqlite+aiosqlite:///./mlops_chat.db` |
| `ENABLE_AUTH` | ì¸ì¦ í™œì„±í™” | `false` |
| `API_KEY` | API í‚¤ (ì¸ì¦ ì‹œ) | `your-secret-api-key` |
| `DEFAULT_TEMPERATURE` | LLM ì˜¨ë„ | `0.7` |
| `DEFAULT_MAX_TOKENS` | ìµœëŒ€ í† í° | `512` |
| `LOG_DIR` | ë¡œê·¸ ë””ë ‰í† ë¦¬ | `./logs/fastapi` |
| `HUGGINGFACE_TOKEN` | Gated ëª¨ë¸ ì ‘ê·¼ | - |
| `MODEL_CACHE_DIR` | ëª¨ë¸ ìºì‹œ ê²½ë¡œ | `models/downloaded` |
| `OFFLINE_MODE` | ì˜¤í”„ë¼ì¸ ëª¨ë“œ | `false` |
| `ADMIN_USERNAME` | ê´€ë¦¬ì ID | `admin` |
| `ADMIN_PASSWORD` | ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸ | `changeme` |
| `JWT_SECRET_KEY` | JWT ì„œëª… í‚¤ | `change-this-...` |

### 3. GPU í™˜ê²½ í™•ì¸

```bash
python src/check_gpu.py
```

## Phaseë³„ ê°€ì´ë“œ

### Phase 0: í™˜ê²½ ì¤€ë¹„ âœ… ì™„ë£Œ
- [x] í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
- [x] ê°€ìƒí™˜ê²½ ì„¤ì •
- [x] requirements.txt ì‘ì„±
- [x] GPU í™˜ê²½ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
- [x] GPU í™˜ê²½ ê²€ì¦ (RTX 5090 + RTX 5060 Ti)

### Phase 1: ë² ì´ìŠ¤ ì±—ë´‡ âœ… ì™„ë£Œ
- [x] LLaMA-3-8B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [x] ê¸°ë³¸ LLM ë¡œë“œ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸
- [x] Gradio UI ë°ëª¨

### Phase 2: Fine-tuning âœ… ì™„ë£Œ
- [x] í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (HuggingFace no_robots: 9,499 examples)
- [x] í•©ì„± ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (MLOps/DevOps íŠ¹í™”)
- [x] LoRA fine-tuning
- [x] QLoRA fine-tuning (4-bit)
- [x] MLflow ì‹¤í—˜ ì¶”ì  ì„¤ì •
- [x] ëª¨ë¸ ë°°í¬ (HuggingFace Hub)

### Phase 3: ìµœì í™” ğŸ”„ ì§„í–‰ ì¤‘
- [x] vLLM ì„œë¹™ êµ¬ì¶•
- [ ] Prompt Engineering
- [ ] LangChain íŒŒì´í”„ë¼ì¸
- [ ] ì„±ëŠ¥ ìµœì í™”

### Phase 4: í”„ë¡œë•ì…˜í™” ğŸ”„ ì§„í–‰ ì¤‘
- [x] FastAPI ë°±ì—”ë“œ (í´ë¦° ì•„í‚¤í…ì²˜ ì ìš©)
- [x] SQLAlchemy + Alembic DB ì„¤ì •
- [x] SQLAdmin ê´€ë¦¬ì ì¸í„°í˜ì´ìŠ¤
- [ ] ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
- [x] Docker ì»¨í…Œì´ë„ˆí™” (ìŠ¤íƒë³„ ë¶„ë¦¬)
- [x] ëª¨ë‹ˆí„°ë§ (Prometheus + Grafana + Loki + Alloy)
  - 6ê°œì˜ Grafana ëŒ€ì‹œë³´ë“œ (System Overview, Training/Inference Metrics & Detail, Logs)
  - êµ¬ì¡°í™”ëœ JSON ë¡œê¹… (training, inference, system, api)
  - LogQL ê¸°ë°˜ ë¡œê·¸ ì¿¼ë¦¬
- [ ] CI/CD íŒŒì´í”„ë¼ì¸

> ğŸ“– **ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ ìƒì„¸**: [deployment/README.md](deployment/README.md)

## í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´
- **GPU**: NVIDIA GPU 16GB+ VRAM (í˜„ì¬: RTX 5090 31GB + RTX 5060 Ti 15GB)
- **RAM**: 32GB+ ê¶Œì¥
- **Storage**: 50GB+ ì—¬ìœ  ê³µê°„ (ëª¨ë¸ ì €ì¥ìš©)

### ì†Œí”„íŠ¸ì›¨ì–´
- Python 3.10+
- CUDA 11.8+ (GPU ì‚¬ìš© ì‹œ)
- Docker (ë°°í¬ ì‹œ)
- Git

### API í‚¤ (ì„ íƒ)
- HuggingFace Token (Gated ëª¨ë¸ ì‚¬ìš© ì‹œ)
- OpenAI API Key (í•©ì„± ë°ì´í„° ìƒì„± ì‹œ)

## ì£¼ìš” ëª…ë ¹ì–´

### ê°œë°œ í™˜ê²½

```bash
# pyenv ê°€ìƒí™˜ê²½ (ìë™ í™œì„±í™” - .python-version)
cd /path/to/mlops-project  # mlops-project í™˜ê²½ ìë™ ì ìš©

# GPU ë° í™˜ê²½ í™•ì¸
python src/check_gpu.py

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
python -m src.utils.download_model meta-llama/Llama-3.1-8B-Instruct
python -m src.utils.download_model --list  # ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ëª©ë¡

# í•™ìŠµ
python src/train/01_lora_finetune.py      # LoRA
python src/train/02_qlora_finetune.py     # QLoRA
mlflow ui --port 5000

# ì„œë¹™
python src/serve/01_vllm_server.py        # vLLM :8000
python -m src.serve.main                  # FastAPI :8080 (í´ë¦° ì•„í‚¤í…ì²˜)

# í…ŒìŠ¤íŠ¸
python -m pytest tests/serve/ -v

# DB ë§ˆì´ê·¸ë ˆì´ì…˜ (Alembic) - í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
alembic current                           # í˜„ì¬ ìƒíƒœ
alembic revision --autogenerate -m "ì„¤ëª…"  # ë§ˆì´ê·¸ë ˆì´ì…˜ ìƒì„±
alembic upgrade head                       # ì ìš©
```

### í”„ë¡œë•ì…˜ ë°°í¬ (Docker)

Docker Composeë¥¼ í†µí•´ MLOps ì „ì²´ ìŠ¤íƒì„ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# ì „ì²´ ìŠ¤íƒ ì‹¤í–‰
docker compose -f docker/docker-compose.yml up -d

# ê°œë³„ ìŠ¤íƒ ì‹¤í–‰
docker compose -f docker/docker-compose.mlflow.yml up -d      # MLflow ìŠ¤íƒ
docker compose -f docker/docker-compose.serving.yml up -d     # Serving ìŠ¤íƒ
docker compose -f docker/docker-compose.monitoring.yml up -d  # Monitoring ìŠ¤íƒ

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker compose -f docker/docker-compose.yml ps

# ë¡œê·¸ í™•ì¸
docker compose -f docker/docker-compose.yml logs -f [service-name]

# ì¤‘ì§€
docker compose -f docker/docker-compose.yml down
```

**ì£¼ìš” ì„œë¹„ìŠ¤ í¬íŠ¸:**
- MLflow UI: http://localhost:5050
- vLLM OpenAI API: http://localhost:8000/docs
- FastAPI: http://localhost:8080/docs
- Grafana: http://localhost:3000 (admin/admin)
- Prometheus: http://localhost:9090
- Alloy UI: http://localhost:12345

> ğŸ“– **ìƒì„¸ ë°°í¬ ê°€ì´ë“œ**: [deployment/README.md](deployment/README.md)ì—ì„œ ë¡œê·¸ êµ¬ì¡°, ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ, ë°±ì—…, ì„±ëŠ¥ íŠœë‹, íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë“± ì „ì²´ ë°°í¬ ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Out of Memory (OOM)
- Batch size ì¤„ì´ê¸°
- QLoRA ì‚¬ìš© (4-bit ì–‘ìí™”)
- Gradient checkpointing í™œì„±í™”

### ëŠë¦° í•™ìŠµ ì†ë„
- Mixed precision (fp16/bf16) ì‚¬ìš©
- Gradient accumulation í™œìš©
- Flash Attention ì ìš©

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
- HuggingFace í† í° í™•ì¸
- ì¸í„°ë„· ì—°ê²° í™•ì¸
- ìºì‹œ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸

## ìƒì„¸ ë¬¸ì„œ

### ì‚¬ìš©ì ê°€ì´ë“œ
- [**ë°°í¬ ê°€ì´ë“œ**](deployment/README.md) - Docker Compose ë°°í¬, ëª¨ë‹ˆí„°ë§, ë¡œê·¸ ê´€ë¦¬, ë°±ì—…, íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- [vLLM ì„œë²„ ê°€ì´ë“œ](docs/references/VLLM.md) - vLLM ì„œë¹™ ìƒì„¸ ê°€ì´ë“œ
- [ë¡œê¹… ì‹œìŠ¤í…œ ê°€ì´ë“œ](docs/references/LOGGING.md) - êµ¬ì¡°í™”ëœ ë¡œê¹… ì‚¬ìš©ë²•
- [Grafana ë“œë¦´ë‹¤ìš´ ì›Œí¬í”Œë¡œìš°](docs/references/GRAFANA_DRILLDOWN_WORKFLOW.md) - ëŒ€ì‹œë³´ë“œ í™œìš©ë²•

### ê°œë°œ ë¬¸ì„œ
- [í´ë¦° ì•„í‚¤í…ì²˜ ë¦¬íŒ©í† ë§ ê³„íš](docs/plans/clean-architecture-refactoring.md) - ë¦¬íŒ©í† ë§ ë¡œë“œë§µ
- [Docker êµ¬ì¡° ì¬í¸ ê³„íš](docs/plans/docker-compose-restructure.md) - Docker Compose ë¶„ë¦¬

### AI ì—ì´ì „íŠ¸ìš© ê°€ì´ë“œ
- [deployment/CLAUDE.md](deployment/CLAUDE.md) - ë°°í¬ ê°„ëµ ê°€ì´ë“œ (AIìš©)

## ì°¸ê³  ìë£Œ

- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [PEFT Documentation](https://huggingface.co/docs/peft)
- [vLLM Documentation](https://vllm.readthedocs.io/)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [LangChain Documentation](https://python.langchain.com/)
