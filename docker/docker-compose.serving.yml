services:
  vllm-server:
    build:
      context: ..
      dockerfile: deployment/serving/Dockerfile.vllm
    container_name: mlops-vllm
    environment:
      # 모델 1 설정 (GPU 0)
      MODEL_1_ENABLED: ${MODEL_1_ENABLED:-true}
      MODEL_1_PATH: ${MODEL_1_PATH:-/models/base/meta-llama/Meta-Llama-3-8B-Instruct}
      MODEL_1_GPU: ${MODEL_1_GPU:-0}
      MODEL_1_PORT: ${MODEL_1_PORT:-8000}
      MODEL_1_GPU_MEMORY: ${MODEL_1_GPU_MEMORY:-0.9}
      MODEL_1_MAX_LEN: ${MODEL_1_MAX_LEN:-4096}
      # 모델 2 설정 (GPU 1)
      MODEL_2_ENABLED: ${MODEL_2_ENABLED:-false}
      MODEL_2_PATH: ${MODEL_2_PATH:-}
      MODEL_2_GPU: ${MODEL_2_GPU:-1}
      MODEL_2_PORT: ${MODEL_2_PORT:-8001}
      MODEL_2_GPU_MEMORY: ${MODEL_2_GPU_MEMORY:-0.9}
      MODEL_2_MAX_LEN: ${MODEL_2_MAX_LEN:-4096}
    volumes:
      - ../models:/models
      - ../logs/vllm:/logs
    ports:
      - "${MODEL_1_PORT:-8000}:${MODEL_1_PORT:-8000}"
      - "${MODEL_2_PORT:-8001}:${MODEL_2_PORT:-8001}"
    networks:
      - mlops-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0', '1']
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${MODEL_1_PORT:-8000}/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  fastapi-server:
    build:
      context: ..
      dockerfile: deployment/serving/Dockerfile.fastapi
    container_name: mlops-fastapi
    environment:
      VLLM_BASE_URL: ${VLLM_BASE_URL:-http://localhost:8000/v1}
      FASTAPI_HOST: 0.0.0.0
      FASTAPI_PORT: 8080
      DATABASE_URL: sqlite+aiosqlite:///./data/mlops_chat.db
      DEBUG: "false"
      ENABLE_AUTH: "false"
      CORS_ORIGINS: '["*"]'
    volumes:
      - ../src:/app/src
      - ../logs/fastapi:/logs
      - ../alembic.ini:/app/alembic.ini
      - fastapi_data:/app/data
    ports:
      - "${FASTAPI_EXTERNAL_PORT:-8080}:8080"
    networks:
      - mlops-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  mlops-network:
    name: mlops-network

volumes:
  fastapi_data:
