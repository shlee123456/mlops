FROM nvidia/cuda:12.1.0-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create symbolic links
RUN ln -s /usr/bin/python3 /usr/bin/python

# Install PyTorch with CUDA support
RUN pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Install vLLM and dependencies
# numpy<2 required for vllm 0.2.7 compatibility
RUN pip install --no-cache-dir \
    "numpy<2" \
    vllm==0.2.7 \
    transformers==4.36.0 \
    accelerate==0.25.0 \
    sentencepiece \
    protobuf

# Copy application code
COPY src/ /app/src/

# Copy startup script
COPY deployment/serving/start-vllm.sh /app/start-vllm.sh
RUN chmod +x /app/start-vllm.sh

# Create logs directory
RUN mkdir -p /logs

# Expose ports for both models
EXPOSE 8000 8001

# Healthcheck (checks Model 1 by default)
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s --retries=3 \
    CMD curl -f http://localhost:${MODEL_1_PORT:-8000}/health || exit 1

# Start vLLM servers via startup script
CMD ["/app/start-vllm.sh"]
