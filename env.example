# MLOps Chatbot 환경설정
# 이 파일을 .env로 복사 후 값을 수정하세요: cp env.example .env

# =============================================================================
# 앱 설정
# =============================================================================
DEBUG=false

# =============================================================================
# 서버 설정
# =============================================================================
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8080

# =============================================================================
# vLLM 설정
# =============================================================================
VLLM_BASE_URL=http://localhost:8000/v1
DEFAULT_MODEL=

# =============================================================================
# 데이터베이스
# =============================================================================
DATABASE_URL=sqlite+aiosqlite:///./mlops_chat.db
DATABASE_ECHO=false

# =============================================================================
# 인증
# =============================================================================
ENABLE_AUTH=false
API_KEY=your-secret-api-key

# =============================================================================
# LLM 기본값
# =============================================================================
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=512
DEFAULT_TOP_P=0.9

# =============================================================================
# 로깅
# =============================================================================
LOG_DIR=./logs/fastapi

# =============================================================================
# HuggingFace (Gated 모델 접근 시 필수)
# =============================================================================
HUGGINGFACE_TOKEN=

# =============================================================================
# 모델 다운로드 설정
# =============================================================================
# 모델 캐시 디렉토리 (기본: HuggingFace 캐시)
MODEL_CACHE_DIR=models/downloaded
# 오프라인 모드 - 로컬 파일만 사용 (사전 다운로드 필요)
OFFLINE_MODE=false

# =============================================================================
# Admin 설정
# =============================================================================
ADMIN_USERNAME=admin
ADMIN_PASSWORD=changeme
JWT_SECRET_KEY=change-this-secret-key-in-production
JWT_ALGORITHM=HS256
ADMIN_TOKEN_EXPIRE_MINUTES=60

# =============================================================================
# Docker 서비스 포트 설정
# =============================================================================
# MLflow 스택
POSTGRES_PORT=5432
POSTGRES_USER=mlflow
POSTGRES_PASSWORD=mlflow
POSTGRES_DB=mlflow

MINIO_PORT=9000
MINIO_CONSOLE_PORT=9001
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minio123

MLFLOW_PORT=5050

# Serving 스택
FASTAPI_EXTERNAL_PORT=8080

# =============================================================================
# vLLM 다중 모델 설정
# =============================================================================
# 모델 1 (GPU 0: RTX 5090, 32GB)
MODEL_1_ENABLED=true
MODEL_1_PATH=/models/base/meta-llama/Meta-Llama-3-8B-Instruct
MODEL_1_GPU=0
MODEL_1_PORT=8000
MODEL_1_GPU_MEMORY=0.9
MODEL_1_MAX_LEN=4096

# 모델 2 (GPU 1: RTX 5060 Ti, 16GB)
MODEL_2_ENABLED=false
MODEL_2_PATH=
MODEL_2_GPU=1
MODEL_2_PORT=8001
MODEL_2_GPU_MEMORY=0.9
MODEL_2_MAX_LEN=4096

# Monitoring 스택
LOKI_PORT=3100
ALLOY_PORT=12345
PROMETHEUS_PORT=9090
GRAFANA_PORT=3000

GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin
